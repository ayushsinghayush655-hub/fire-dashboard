<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Face Recognition System</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="https://cdn.jsdelivr.net/npm/face-api.js@0.22.2/dist/face-api.min.js"></script>
    
    <style>
        body { background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); }
        .loader { border-top-color: #3498db; animation: spin 1s linear infinite; }
        @keyframes spin { to { transform: rotate(360deg); } }
        .progress-bar {
            background-color: #4a5568;
            background-image: linear-gradient(45deg, rgba(255, 255, 255, .15) 25%, transparent 25%, transparent 50%, rgba(255, 255, 255, .15) 50%, rgba(255, 255, 255, .15) 75%, transparent 75%, transparent);
            background-size: 1rem 1rem;
            animation: progress-bar-stripes 1s linear infinite;
        }
        @keyframes progress-bar-stripes {
            from { background-position: 1rem 0; }
            to { background-position: 0 0; }
        }
    </style>
</head>
<body class="bg-gray-100 font-sans text-gray-800">
    <div id="loadingOverlay" class="fixed inset-0 bg-black bg-opacity-75 flex flex-col items-center justify-center z-50">
        <div class="loader ease-linear rounded-full border-8 border-t-8 border-gray-200 h-24 w-24 mb-4"></div>
        <h2 class="text-center text-white text-xl font-semibold">Initializing System...</h2>
        <p id="loadingText" class="w-2/3 md:w-1/3 text-center text-white mt-2 leading-relaxed">Loading High-Accuracy AI models...</p>
    </div>

    <div class="container mx-auto p-4 md:p-8">
         <header class="text-center text-white mb-8">
            <h1 class="text-4xl md:text-5xl font-bold">üéØ Face Recognition System</h1>
            <p class="text-lg mt-2">High-Accuracy Recognition with Local Storage</p>
        </header>
        
        <div class="grid grid-cols-2 md:grid-cols-4 gap-4 md:gap-6 mb-8">
            <div class="bg-white p-4 rounded-xl shadow-lg text-center">
                <div class="text-3xl font-bold text-indigo-600" id="totalPeople">0</div>
                <div class="text-gray-500">Registered People</div>
            </div>
            <div class="bg-white p-4 rounded-xl shadow-lg text-center">
                <div class="text-3xl font-bold text-indigo-600" id="todayScans">0</div>
                <div class="text-gray-500">Today's Scans</div>
            </div>
            <div class="bg-white p-4 rounded-xl shadow-lg text-center">
                <div class="text-3xl font-bold text-indigo-600">99.8%</div>
                <div class="text-gray-500">Target Accuracy</div>
            </div>
            <div class="bg-white p-4 rounded-xl shadow-lg text-center">
                <div class="text-3xl font-bold text-indigo-600">68</div>
                <div class="text-gray-500">Face Points</div>
            </div>
        </div>

        <div class="grid grid-cols-1 lg:grid-cols-2 gap-8 mb-8">
            <div class="bg-white p-6 rounded-xl shadow-lg">
                <h2 class="text-2xl font-bold mb-4">üìπ Live Camera Recognition</h2>
                <div class="relative w-full aspect-video bg-black rounded-lg mb-4">
                    <video id="video" class="w-full h-full rounded-lg" autoplay muted playsinline></video>
                    <canvas id="canvas" class="absolute top-0 left-0 w-full h-full"></canvas>
                    <div id="cameraStatus" class="absolute bottom-2 left-2 bg-black bg-opacity-50 text-white text-xs px-2 py-1 rounded">Camera Off</div>
                </div>
                <div class="flex flex-wrap gap-2 mb-4">
                    <button id="startBtn" class="flex-grow bg-green-500 text-white px-4 py-2 rounded-lg font-semibold hover:bg-green-600 transition">Start Camera</button>
                    <button id="stopBtn" class="flex-grow bg-red-500 text-white px-4 py-2 rounded-lg font-semibold hover:bg-red-600 transition" disabled>Stop Camera</button>
                </div>
                <div id="cameraResults" class="bg-gray-50 p-4 rounded-lg min-h-[100px]">
                    <p class="text-gray-500">Click "Start Camera" to begin face recognition.</p>
                </div>
            </div>

            <div class="bg-white p-6 rounded-xl shadow-lg">
                <h2 class="text-2xl font-bold mb-4">üñºÔ∏è Image Recognition</h2>
                <input type="file" id="imageInput" class="block w-full text-sm text-gray-500 file:mr-4 file:py-2 file:px-4 file:rounded-full file:border-0 file:text-sm file:font-semibold file:bg-indigo-50 file:text-indigo-700 hover:file:bg-indigo-100 mb-4" accept="image/*" multiple>
                <div class="flex flex-wrap gap-2 mb-4">
                    <button id="analyzeBtn" class="flex-grow bg-indigo-500 text-white px-4 py-2 rounded-lg font-semibold hover:bg-indigo-600 transition">Analyze Images</button>
                    <button id="clearBtn" class="flex-grow bg-gray-500 text-white px-4 py-2 rounded-lg font-semibold hover:bg-gray-600 transition">Clear Results</button>
                </div>
                <div id="imageResults" class="bg-gray-50 p-4 rounded-lg min-h-[100px] max-h-80 overflow-y-auto">
                    <p class="text-gray-500">Upload images to start recognition.</p>
                </div>
            </div>
        </div>
        
        <!-- Video Scan Section -->
        <div class="bg-white p-6 rounded-xl shadow-lg mb-8">
            <h2 class="text-2xl font-bold mb-4">üé¨ Video Scan</h2>
            <input type="file" id="videoInput" class="block w-full text-sm text-gray-500 file:mr-4 file:py-2 file:px-4 file:rounded-full file:border-0 file:text-sm file:font-semibold file:bg-indigo-50 file:text-indigo-700 hover:file:bg-indigo-100 mb-4" accept="video/*">
            <div class="relative w-full aspect-video bg-black rounded-lg mb-4 hidden" id="videoScanPlayerWrapper">
                <video id="videoScanPlayer" class="w-full h-full rounded-lg" controls></video>
                <canvas id="videoScanCanvas" class="absolute top-0 left-0 w-full h-full pointer-events-none"></canvas>
            </div>
            <div class="flex flex-wrap gap-2 mb-4">
                <button id="analyzeVideoBtn" class="flex-grow bg-indigo-500 text-white px-4 py-2 rounded-lg font-semibold hover:bg-indigo-600 transition" disabled>Scan Video</button>
                <button id="clearVideoBtn" class="flex-grow bg-gray-500 text-white px-4 py-2 rounded-lg font-semibold hover:bg-gray-600 transition" disabled>Clear Video</button>
            </div>
            <div id="videoScanProgress" class="hidden">
                 <div class="w-full bg-gray-200 rounded-full h-2.5">
                    <div id="videoProgressBar" class="bg-blue-600 h-2.5 rounded-full progress-bar" style="width: 0%"></div>
                </div>
                <p id="videoProgressText" class="text-center text-sm mt-1">Processing...</p>
            </div>
            <div id="videoResults" class="bg-gray-50 p-4 rounded-lg min-h-[50px] mt-2">
                <p class="text-gray-500">Upload a video to begin recognition.</p>
            </div>
        </div>

        <div class="bg-white p-6 rounded-xl shadow-lg">
            <h2 class="text-2xl font-bold mb-4">üë• Face Database</h2>
            <p class="text-sm text-gray-500 -mt-3 mb-4">Storage is limited only by your browser's capacity (supports thousands of entries).</p>
            <div class="flex flex-wrap gap-2 mb-4">
                <button id="addPersonBtn" class="bg-green-500 text-white px-4 py-2 rounded-lg font-semibold hover:bg-green-600 transition">Add New Person</button>
                <button id="trainBtn" class="bg-indigo-500 text-white px-4 py-2 rounded-lg font-semibold hover:bg-indigo-600 transition">Re-Train Model</button>
                <button id="resetBtn" class="bg-red-500 text-white px-4 py-2 rounded-lg font-semibold hover:bg-red-600 transition">Reset Database</button>
            </div>
            
            <div id="addPersonForm" class="hidden bg-gray-100 p-4 rounded-lg my-4" style="position: relative;">
                <div class="form-content">
                    <h3 class="text-xl font-bold mb-3">Register New Person</h3>
                    <div class="grid grid-cols-1 md:grid-cols-2 gap-4 mb-4">
                        <input type="text" id="personName" placeholder="Full Name" class="p-2 border rounded-lg w-full" required>
                        <input type="text" id="personId" placeholder="Auto-generated ID" class="p-2 border rounded-lg w-full bg-gray-200" readonly>
                        <select id="personType" class="p-2 border rounded-lg w-full">
                            <option value="student">Student</option><option value="faculty">Faculty</option><option value="staff">Staff</option><option value="visitor">Visitor</option>
                        </select>
                        <div class="md:col-span-2">
                            <label class="block text-sm font-medium text-gray-700 mb-1">Upload at least one clear face photo:</label>
                            <input type="file" id="personImages" accept="image/*" multiple class="block w-full text-sm text-gray-500 file:mr-4 file:py-2 file:px-4 file:rounded-full file:border-0 file:text-sm file:font-semibold file:bg-indigo-50 file:text-indigo-700 hover:file:bg-indigo-100" required>
                        </div>
                    </div>
                    <div class="flex gap-2">
                        <button id="savePersonBtn" class="bg-green-500 text-white px-4 py-2 rounded-lg font-semibold hover:bg-green-600 transition flex items-center justify-center gap-2">
                            <span id="saveBtnText">Save Person</span>
                            <div id="saveBtnLoader" class="hidden w-5 h-5 border-2 border-white border-t-transparent rounded-full animate-spin"></div>
                        </button>
                        <button id="cancelBtn" class="bg-gray-500 text-white px-4 py-2 rounded-lg font-semibold hover:bg-gray-600 transition">Cancel</button>
                    </div>
                </div>
            </div>

            <div id="peopleGrid" class="grid grid-cols-1 sm:grid-cols-2 md:grid-cols-3 lg:grid-cols-4 xl:grid-cols-5 gap-4">
                 <!-- Person cards will be dynamically inserted here -->
            </div>
        </div>
    </div>

    <div id="toast" class="fixed top-5 right-5 bg-green-500 text-white px-6 py-3 rounded-lg shadow-lg text-lg opacity-0 translate-x-full transition-all duration-500">
        <p id="toastMessage"></p>
    </div>

    <script>
        const video = document.getElementById('video');
        const canvas = document.getElementById('canvas');
        const loadingOverlay = document.getElementById('loadingOverlay');
        const loadingText = document.getElementById('loadingText');
        
        let database = [];
        let faceMatcher = null;
        let videoStream = null;
        let recognitionLoopId = null;
        let scanCount = 0;
        
        const MODEL_URL = 'https://justadudewhohacks.github.io/face-api.js/models';
        const CONFIDENCE_THRESHOLD = 0.5;
        const DETECTION_INTERVAL = 400; // ms for live camera
        
        const defaultDatabase = [
             { id: 'STU001', name: 'John Smith', type: 'student', registered: '2025-01-15', descriptors: [] },
             { id: 'FAC001', name: 'Dr. Sarah Wilson', type: 'faculty', registered: '2025-01-10', descriptors: [] }
        ];

        async function init() {
            try {
                loadingText.textContent = 'Loading Face Detector (SSD Mobilenet V1)...';
                await faceapi.nets.ssdMobilenetv1.loadFromUri(MODEL_URL);
                loadingText.textContent = 'Loading Face Landmark Model...';
                await faceapi.nets.faceLandmark68Net.loadFromUri(MODEL_URL);
                loadingText.textContent = 'Loading Face Recognition Model...';
                await faceapi.nets.faceRecognitionNet.loadFromUri(MODEL_URL);
                
                loadingOverlay.style.display = 'none';
                showToast('success', 'System Initialized Successfully!');
                
                loadDatabase();
                setupEventListeners();
                updateDisplay();
                updateFaceMatcher();
            } catch (error) {
                loadingText.textContent = `Failed to load AI models. Please refresh. Error: ${error.message}`;
                showToast('error', 'Model loading failed!');
            }
        }

        function setupEventListeners() {
            // Live camera
            document.getElementById('startBtn').addEventListener('click', startCamera);
            document.getElementById('stopBtn').addEventListener('click', stopCamera);
            
            // Image recognition
            document.getElementById('analyzeBtn').addEventListener('click', analyzeImages);
            document.getElementById('clearBtn').addEventListener('click', clearImageResults);
            
            // Video Scan
            document.getElementById('videoInput').addEventListener('change', handleVideoUpload);
            document.getElementById('analyzeVideoBtn').addEventListener('click', analyzeVideo);
            document.getElementById('clearVideoBtn').addEventListener('click', clearVideo);

            // Database
            document.getElementById('addPersonBtn').addEventListener('click', showAddForm);
            document.getElementById('savePersonBtn').addEventListener('click', savePerson);
            document.getElementById('cancelBtn').addEventListener('click', hideAddForm);
            document.getElementById('trainBtn').addEventListener('click', () => {
                showToast('info', 'Re-training model from local data...');
                updateFaceMatcher();
            });
            document.getElementById('resetBtn').addEventListener('click', resetDatabase);
            document.getElementById('personType').addEventListener('change', generateId);
        }

        async function startCamera() {
            try {
                if (videoStream) stopCamera();
                videoStream = await navigator.mediaDevices.getUserMedia({ video: {} });
                video.srcObject = videoStream;
                document.getElementById('startBtn').disabled = true;
                document.getElementById('stopBtn').disabled = false;
                document.getElementById('cameraStatus').textContent = 'Camera Active';
                showToast('success', 'Camera started successfully!');
                video.addEventListener('play', startRecognition);
            } catch (error) {
                showToast('error', 'Could not access camera. Please grant permission.');
                console.error('Camera error:', error);
            }
        }

        function stopCamera() {
            if (videoStream) {
                videoStream.getTracks().forEach(track => track.stop());
                videoStream = null;
            }
            if (recognitionLoopId) {
                cancelAnimationFrame(recognitionLoopId);
                recognitionLoopId = null;
            }
            const context = canvas.getContext('2d');
            if (context) { context.clearRect(0, 0, canvas.width, canvas.height); }
            document.getElementById('startBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
            document.getElementById('cameraStatus').textContent = 'Camera Off';
            document.getElementById('cameraResults').innerHTML = '<p class="text-gray-500">Recognition stopped.</p>';
            showToast('info', 'Camera stopped.');
        }
        
        function startRecognition() {
            let lastDetectionTime = 0;
            let lastResults = [];

            async function recognitionLoop(currentTime) {
                if (!videoStream) return;

                const context = canvas.getContext('2d');
                const displaySize = { width: video.clientWidth, height: video.clientHeight };
                faceapi.matchDimensions(canvas, displaySize);
                context.clearRect(0, 0, canvas.width, canvas.height);

                if (currentTime - lastDetectionTime > DETECTION_INTERVAL) {
                    lastDetectionTime = currentTime;

                    const detections = await faceapi.detectAllFaces(video, new faceapi.SsdMobilenetv1Options()).withFaceLandmarks().withFaceDescriptors();
                    const resizedDetections = faceapi.resizeResults(detections, displaySize);

                    if (detections.length > 0 && faceMatcher) {
                        lastResults = detections.map((d, i) => ({
                            match: faceMatcher.findBestMatch(d.descriptor),
                            box: resizedDetections[i].detection.box
                        }));
                        displayCameraResults(lastResults.map(r => r.match));
                    } else if (detections.length > 0) {
                        lastResults = resizedDetections.map(d => ({ match: { label: 'unknown' }, box: d.detection.box }));
                        displayCameraResults(lastResults.map(r => r.match));
                    } else {
                        lastResults = [];
                        document.getElementById('cameraResults').innerHTML = '<p class="text-gray-500">Searching for faces...</p>';
                    }
                }

                lastResults.forEach(result => {
                    const isUnknown = result.match.label === 'unknown' || result.match.distance > CONFIDENCE_THRESHOLD;
                    const name = isUnknown ? 'Unknown' : result.match.label.split(' (')[0];
                    const confidence = (1 - result.match.distance).toFixed(2);
                    const label = isUnknown ? 'Unknown' : `${name} (${confidence})`;
                    new faceapi.draw.DrawBox(result.box, { label, boxColor: isUnknown ? '#dc2626' : '#16a34a' }).draw(canvas);
                });

                recognitionLoopId = requestAnimationFrame(recognitionLoop);
            }
            recognitionLoopId = requestAnimationFrame(recognitionLoop);
        }

        function displayCameraResults(results) {
             const resultsContainer = document.getElementById('cameraResults');
            if (results.length === 0) return;
            resultsContainer.innerHTML = '';
            let unknownCount = 0;
            results.forEach(result => {
                const isUnknown = result.label === 'unknown' || result.distance > CONFIDENCE_THRESHOLD;
                if (isUnknown) unknownCount++;
                const personName = isUnknown ? `Unknown Person #${unknownCount}` : result.label.split(' (')[0];
                const confidence = isUnknown ? 'N/A' : (1 - result.distance).toFixed(2);
                let borderColorClass = isUnknown ? 'border-red-500' : 'border-green-500';
                resultsContainer.innerHTML += `<div class="p-3 mb-2 rounded-lg border-l-4 ${borderColorClass} bg-gray-50"><div class="font-bold">${personName}</div><div>Confidence: ${confidence}</div></div>`;
                if (!isUnknown && !document.body.hasAttribute(`data-scanned-${personName.replace(/\s+/g, '')}`)) {
                    scanCount++;
                    document.getElementById('todayScans').textContent = scanCount;
                    document.body.setAttribute(`data-scanned-${personName.replace(/\s+/g, '')}`, 'true');
                    saveDatabase();
                }
            });
        }
        
        async function analyzeImages() {
             const files = document.getElementById('imageInput').files;
            if (files.length === 0 || !faceMatcher) { showToast('warning', 'Please select images and ensure model is trained.'); return; }
            showToast('info', `Analyzing ${files.length} image(s)...`);
            const resultsContainer = document.getElementById('imageResults');
            resultsContainer.innerHTML = '';
            for (const file of files) {
                const image = await faceapi.bufferToImage(file);
                const detections = await faceapi.detectAllFaces(image, new faceapi.SsdMobilenetv1Options()).withFaceLandmarks().withFaceDescriptors();
                let fileResultHtml = `<div class="p-3 mb-2 rounded-lg border-l-4 border-gray-300 bg-gray-50"><strong>üìÅ ${file.name}</strong>`;
                if (detections.length > 0) {
                    const results = detections.map(d => faceMatcher.findBestMatch(d.descriptor));
                    results.forEach(result => {
                         const personName = result.label === 'unknown' ? 'Unknown' : result.label.split(' (')[0];
                         const confidence = (1 - result.distance).toFixed(2);
                         fileResultHtml += `<div class="ml-4 mt-1 ${result.label === 'unknown' ? 'text-red-600' : 'text-green-600'}">‚úÖ Found: ${personName} (Confidence: ${confidence})</div>`;
                    });
                } else { fileResultHtml += `<div class="ml-4 mt-1 text-red-600">‚ùå No faces detected.</div>`; }
                fileResultHtml += `</div>`;
                resultsContainer.innerHTML += fileResultHtml;
            }
        }

        function clearImageResults() {
            document.getElementById('imageResults').innerHTML = '<p class="text-gray-500">Upload images to start recognition.</p>';
            document.getElementById('imageInput').value = '';
        }

        // --- Video Scan Functions ---
        let videoFile = null;
        let videoScanLoopId = null;

        function handleVideoUpload(event) {
            videoFile = event.target.files[0];
            if (!videoFile) return;
            const player = document.getElementById('videoScanPlayer');
            player.src = URL.createObjectURL(videoFile);
            document.getElementById('videoScanPlayerWrapper').classList.remove('hidden');
            document.getElementById('analyzeVideoBtn').disabled = false;
            document.getElementById('clearVideoBtn').disabled = false;
            document.getElementById('videoResults').innerHTML = `<p class="text-gray-500">Video loaded. Click "Scan Video" to begin.</p>`;
        }

        function clearVideo() {
            if (videoScanLoopId) cancelAnimationFrame(videoScanLoopId);
            videoFile = null;
            const player = document.getElementById('videoScanPlayer');
            player.src = '';
            document.getElementById('videoInput').value = '';
            document.getElementById('videoScanPlayerWrapper').classList.add('hidden');
            document.getElementById('videoScanProgress').classList.add('hidden');
            document.getElementById('analyzeVideoBtn').disabled = true;
            document.getElementById('clearVideoBtn').disabled = true;
            document.getElementById('videoResults').innerHTML = `<p class="text-gray-500">Upload a video to begin recognition.</p>`;
            const canvas = document.getElementById('videoScanCanvas');
            const context = canvas.getContext('2d');
            if(context) context.clearRect(0,0,canvas.width, canvas.height);
        }

        async function analyzeVideo() {
            if (!videoFile || !faceMatcher) {
                showToast('warning', 'Please upload a video and ensure the model is trained.');
                return;
            }
            const player = document.getElementById('videoScanPlayer');
            const canvas = document.getElementById('videoScanCanvas');
            const progressWrapper = document.getElementById('videoScanProgress');
            const progressBar = document.getElementById('videoProgressBar');
            const progressText = document.getElementById('videoProgressText');
            
            showToast('info', 'Starting video analysis...');
            progressWrapper.classList.remove('hidden');
            player.play();

            let foundPeople = new Set();
            
            async function loop() {
                if (player.paused || player.ended) {
                    progressText.textContent = 'Analysis complete!';
                     return;
                }

                const detections = await faceapi.detectAllFaces(player, new faceapi.SsdMobilenetv1Options()).withFaceLandmarks().withFaceDescriptors();
                const displaySize = { width: player.clientWidth, height: player.clientHeight };
                faceapi.matchDimensions(canvas, displaySize);
                const resizedDetections = faceapi.resizeResults(detections, displaySize);
                
                const context = canvas.getContext('2d');
                context.clearRect(0, 0, canvas.width, canvas.height);

                resizedDetections.forEach(d => {
                    const match = faceMatcher.findBestMatch(d.descriptor);
                    const isUnknown = match.label === 'unknown' || match.distance > CONFIDENCE_THRESHOLD;
                    const name = isUnknown ? 'Unknown' : match.label.split(' (')[0];
                    new faceapi.draw.DrawBox(d.detection.box, { label: name, boxColor: isUnknown ? '#dc2626' : '#16a34a' }).draw(canvas);
                    if (!isUnknown) foundPeople.add(name);
                });

                const progress = (player.currentTime / player.duration) * 100;
                progressBar.style.width = `${progress}%`;
                progressText.textContent = `Processing... ${Math.round(progress)}%`;

                const resultsContainer = document.getElementById('videoResults');
                resultsContainer.innerHTML = `<strong>Found:</strong> ${foundPeople.size > 0 ? Array.from(foundPeople).join(', ') : 'None so far...'}`;

                videoScanLoopId = requestAnimationFrame(loop);
            }
            videoScanLoopId = requestAnimationFrame(loop);
        }

        // --- Database Functions ---
        function updateFaceMatcher() {
            if (database.length === 0) { faceMatcher = null; return; }
            const labeledDescriptors = database.filter(p => p.descriptors && p.descriptors.length > 0).map(p => 
                new faceapi.LabeledFaceDescriptors( `${p.name} (${p.id})`, p.descriptors.map(d => new Float32Array(Object.values(d))))
            );
            if (labeledDescriptors.length > 0) {
                faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, CONFIDENCE_THRESHOLD);
                showToast('success', 'Face matcher trained!');
            } else { faceMatcher = null; }
        }
        
        function loadDatabase() {
            try {
                const data = JSON.parse(localStorage.getItem('faceRecDB_highAccuracy'));
                if (data) { database = data.database || defaultDatabase; scanCount = data.scanCount || 0; }
                else { database = [...defaultDatabase]; scanCount = 0; }
            } catch (e) { database = [...defaultDatabase]; scanCount = 0; }
        }

        function saveDatabase() {
             localStorage.setItem('faceRecDB_highAccuracy', JSON.stringify({ database, scanCount }));
        }

        function generateId() {
            const type = document.getElementById('personType').value;
            const prefix = type.toUpperCase().substring(0, 3);
            const newNum = database.filter(p => p.id.startsWith(prefix)).length + 1;
            document.getElementById('personId').value = `${prefix}${String(newNum).padStart(3, '0')}`;
        }
        function showAddForm() { 
            document.getElementById('addPersonForm').classList.remove('hidden');
            generateId(); 
        }
        function hideAddForm() { document.getElementById('addPersonForm').classList.add('hidden'); }

        async function savePerson() {
            const name = document.getElementById('personName').value.trim();
            const id = document.getElementById('personId').value.trim();
            const type = document.getElementById('personType').value;
            const files = document.getElementById('personImages').files;
            
            if (!name || !id || files.length === 0) { showToast('error', 'Please fill all fields and upload images.'); return; }
            if (database.some(p => p.id === id)) { showToast('error', 'This ID already exists.'); return; }
            
            const saveBtn = document.getElementById('savePersonBtn');
            const saveBtnText = document.getElementById('saveBtnText');
            const saveBtnLoader = document.getElementById('saveBtnLoader');
            saveBtn.disabled = true;
            saveBtnText.textContent = 'Processing...';
            saveBtnLoader.classList.remove('hidden');

            const descriptors = [];
            for (const file of files) {
                try {
                    const image = await faceapi.bufferToImage(file);
                    const detection = await faceapi.detectSingleFace(image, new faceapi.SsdMobilenetv1Options()).withFaceLandmarks().withFaceDescriptor();
                    if (detection) descriptors.push(detection.descriptor);
                } catch (e) { showToast('warning', `Could not process ${file.name}.`); }
            }
            
            saveBtnText.textContent = 'Save Person';
            saveBtnLoader.classList.add('hidden');
            saveBtn.disabled = false;

            if (descriptors.length === 0) { showToast('error', 'No valid faces detected in uploaded images.'); return; }
            
            database.push({ id, name, type, registered: new Date().toISOString().split('T')[0], descriptors });
            saveDatabase();
            updateFaceMatcher();
            updateDisplay();
            hideAddForm();
            showToast('success', `${name} registered locally!`);
        }

        function deletePerson(id) {
            if (confirm('Are you sure you want to delete this person?')) {
                database = database.filter(p => p.id !== id);
                saveDatabase();
                updateFaceMatcher();
                updateDisplay();
                showToast('success', 'Person deleted.');
            }
        }

        function resetDatabase() {
            if (confirm('Reset database to default? All registered people will be deleted.')) {
                database = [...defaultDatabase];
                scanCount = 0;
                saveDatabase();
                updateFaceMatcher();
                updateDisplay();
                showToast('warning', 'Local database has been reset.');
            }
        }

        function updateDisplay() {
            document.getElementById('totalPeople').textContent = database.length;
            document.getElementById('todayScans').textContent = scanCount;
            const grid = document.getElementById('peopleGrid');
            grid.innerHTML = database.map(person => `
                <div class="bg-gray-50 p-4 rounded-lg text-center shadow">
                    <div class="w-16 h-16 bg-indigo-500 text-white rounded-full flex items-center justify-center text-2xl font-bold mx-auto mb-3">${person.name.charAt(0)}</div>
                    <div class="font-bold">${person.name}</div>
                    <div class="text-sm text-gray-500">${person.id}</div>
                    <div class="text-xs text-gray-400 mb-2">${person.type} | ${person.descriptors ? person.descriptors.length : 0} photos</div>
                    <button class="bg-red-500 text-white text-xs px-3 py-1 rounded-full hover:bg-red-600" onclick="deletePerson('${person.id}')">Delete</button>
                </div>
            `).join('');
        }
        
        function showToast(type, message) {
            const toast = document.getElementById('toast');
            const toastMessage = document.getElementById('toastMessage');
            const typeClasses = { success: 'bg-green-500', error: 'bg-red-500', warning: 'bg-yellow-500', info: 'bg-blue-500' };
            toast.className = toast.className.replace(/bg-\w+-500/g, typeClasses[type]);
            toastMessage.textContent = message;
            toast.classList.remove('opacity-0', 'translate-x-full');
            setTimeout(() => { toast.classList.add('opacity-0', 'translate-x-full'); }, 4000);
        }

        document.addEventListener('DOMContentLoaded', init);

    </script>
</body>
</html>

